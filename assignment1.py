# -*- coding: utf-8 -*-
"""Assignment1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tB8E2WlOkv638L0ZCn5T9ahgZe6ajOZA
"""

import pandas as pd
import numpy as np

df = pd.read_excel("iris.data.xlsx")

df.columns = ["1", "2", "3" ,"4", "5"]
df

newdf = df.drop("5", 1)
newdf

df_normalized = newdf.copy()
for column in df_normalized.columns:
    df_normalized[column] = (df_normalized[column] - df_normalized[column].min()) / (df_normalized[column].max() - df_normalized[column].min())

# Print the normalized data
print(df_normalized)

#step 2
def euclidean_distance(point_a, point_b):
  return np.sqrt(np.sum((point_a - point_b) ** 2))

#step 3: populate the similarity matrix
def create_similarity_matrix(df_normalized):
  m = df_normalized.shape[0]
  similarity_matrix = np.zeros((m, m))

  for i in range(m):
    for j in range(i + 1, m):
      dissimilarity = euclidean_distance(df_normalized.iloc[i].values, df_normalized.iloc[j].values)
      similarity_matrix[i, j] = dissimilarity
      similarity_matrix[j, i] = dissimilarity

  return similarity_matrix

  df_normalized = df_normalized.to_numpy()

similarity_matrix = create_similarity_matrix(df_normalized)

m= len(similarity_matrix)

#Print the similarity matrix
for i in range(m):
  for j in range(m):
    print(similarity_matrix[i][j], end=", ")
  print()

# 2B
def form_clusters(similarity_matrix):
    m = similarity_matrix.shape[0]
    clusters = []  # List to store clusters

    for i in range(m):
        # Calculate the average dissimilarity for the i-th object
        avg_dissimilarity = np.mean(similarity_matrix[i, :])

        # Form the cluster for the i-th object
        cluster = [i]  # Initialize the cluster with the i-th object

        # Add objects to the cluster if their dissimilarity is less than the average similarity
        for j in range(m):
            if i != j and similarity_matrix[i, j] < avg_dissimilarity:
                cluster.append(j)

        clusters.append(cluster)  # Add the formed clusters to the list of clusters

    return clusters

clusters = form_clusters(similarity_matrix)

# Print the clusters
for i, cluster in enumerate(clusters):
    print(f"Cluster {i+1}: {cluster}")

#3A
def is_subset(cluster_a, cluster_b):
    return set(cluster_a).issubset(set(cluster_b))

def remove_subsets(clusters):
    sorted_clusters = sorted(clusters, key=len, reverse=True)
    non_subset_clusters = []

    for cluster in sorted_clusters:
        is_subset_flag = False
        for non_subset_cluster in non_subset_clusters:
            if is_subset(cluster, non_subset_cluster):
                is_subset_flag = True
                break

        # If the current cluster is not a subset, add it to the final list
        if not is_subset_flag:
            non_subset_clusters.append(cluster)

    return non_subset_clusters

# Assuming 'clusters' contains the clusters formed earlier
p_clusters = remove_subsets(clusters)

# Print the non-subset clusters
for i, cluster in enumerate(p_clusters):
    print(f"Cluster {i+1}: {cluster}")

def calculate_similarity(cluster_a, cluster_b):
    intersection = len(set(cluster_a).intersection(set(cluster_b)))
    union = len(set(cluster_a).union(set(cluster_b)))
    return intersection / union

def create_similarity_matrix(clusters):
    p = len(clusters)
    similarity_matrix = np.zeros((p, p))

    for i in range(p):
        for j in range(p):
            similarity_matrix[i, j] = calculate_similarity(clusters[i], clusters[j])

    return similarity_matrix

# Assuming you have 'p_clusters' as the result from step A
similarity_matrix = create_similarity_matrix(p_clusters)

# Print the similarity matrix
print("Similarity Matrix :")
print(similarity_matrix)

# 3C
def merge_clusters(cluster_a, cluster_b):
    return list(set(cluster_a).union(set(cluster_b)))

def find_most_similar_clusters(similarity_matrix):
    p = similarity_matrix.shape[0]
    max_similarity = 0
    most_similar_clusters = (0, 0)

    for i in range(p):
        for j in range(i + 1, p):
            if similarity_matrix[i, j] > max_similarity:
                max_similarity = similarity_matrix[i, j]
                most_similar_clusters = (i, j)

    return most_similar_clusters

# Find the most similar clusters
most_similar_clusters = find_most_similar_clusters(similarity_matrix)
cluster_k, cluster_l = most_similar_clusters

# Merge the most similar clusters
new_cluster = merge_clusters(p_clusters[cluster_k], p_clusters[cluster_l])

print(f"Merged Cluster: {new_cluster}")

# Step 3D: Repeat steps 3A to 3C until desired number of clusters is obtained
desired_num_clusters = 10  # Replace K with your desired number of clusters

while len(p_clusters) > desired_num_clusters:
    # Step 3A: Remove clusters that are subsets of others
    p_clusters = remove_subsets(p_clusters)

    # Step 3B: Create similarity matrix C
    similarity_matrix_C = create_similarity_matrix(p_clusters)

    # Step 3C: Find most similar clusters, merge them, and update p_clusters
    most_similar_clusters = find_most_similar_clusters(similarity_matrix)
    cluster_k, cluster_l = most_similar_clusters

    # Merge the most similar clusters
    new_cluster = merge_clusters(p_clusters[cluster_k], p_clusters[cluster_l])

    # Remove the merged clusters from the list
    p_clusters.pop(cluster_k)
    if cluster_l > cluster_k:
        cluster_l -= 1  # Adjust index after removal of previous cluster
    p_clusters.pop(cluster_l)

    # Add the new merged cluster to the list
    p_clusters.append(new_cluster)


# Print the final merged clusters
for i, cluster in enumerate(p_clusters):
    print(f"Final Cluster {i+1}: {cluster}")

